- - -

layout: post
title: "What are tensors?"
tags:

* Artficial Intelligence
thumbnail\_path: blog/2020-02-23-tensors/scalar-vector-matrix-tensor.png
excerpt: \|
In this blogpost my aim is to provide a short yet concise summary of what tensors are.

- - -

### What exactly is a tensor?

What exactly is a tensor?

![tensors](/../../_site/assets/img/blog/2020-02-23-tensors/scalar-vector-matrix-tensor.png)

A tensor is the basic building block of modern machine learning. In its simplest form, tensors are arrays a multidimensional array to be precise. Think of them as a container of numbers, if you are familiar with NumPy, they are similar to the [numpy’s ndarrays] (https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html.

Tensors can also be used on a GPU to accelerate computing. They are a data structure storing a collection of numbers that are accessible individually through an index. Many types of data—from images to time series, audio, and even sentences—can be represented by tensors.

* A single-dimensional tensor is represented as a vector.
* A two-dimensional tensor is represented as a matrix.

Tensors comes in sizes,there are multiple sizes of tensors. Let’s go through the most basic ones that you’ll run across in deep learning.

We would be using Pytorch deep learning framework in this blogpost, I would be showing you how to implement tensors with it.

From your broswer go to https://colab.research.google.com/, Colab allows you to write and execute Python in your web browser, with free access to GPUs no configuration is required to use Google colab

In PyTorch, tensors can be declared using the simple Tensor object:

```
    import torch
    x = torch.Tensor(3, 3)
```