   hyperparameters control parameters w and b


  hyperparameters (e.g Learning Rate(alpha sign), iterations, hidden layer(L), Hidden units,choice of activation function )


  hyperparameters dont have static values, it varies over time?

https://towardsdatascience.com/hyperparameters-in-deep-learning-927f7b2084dd
  Hyperparameters are varaibles that we need to set before applying a learning algorithm to a dataset.
The challenge with hyperparameters is that there are no magic number that works everywhere. The best numbers depend on each task and each dataset
Hyperparameters can be divided into 2 categories:
1. Optimizer hyperparameters,
2. Model Specific hyperparameters

https://towardsdatascience.com/understanding-hyperparameters-optimization-in-deep-learning-models-concepts-and-tools-357002a3338a
https://towardsdatascience.com/what-are-hyperparameters-and-how-to-tune-the-hyperparameters-in-a-deep-neural-network-d0604917584a


References: Udacity_DeepLearning